---
description: Guide for database architecture, API patterns, and data flow
globs: 
alwaysApply: false
---
# Database, API, and Data Flow Guide

This guide details Octopoda's dual database architecture, data ingestion pipeline, API patterns, and data management strategies, based on the implementation guide.

## 1. Dual Database Architecture
Octopoda uses two distinct databases:

### 1.1. SQLite
- **Purpose:** Stores relational application data.
  - User accounts (hashed credentials), roles, permissions.
  - Application settings.
  - Extracted and processed charging sessions (to avoid re-computation).
- **Technology:** File-based SQLite, accessed via Bun's integrated SQLite client (as per guide, though `package.json` lists `@libsql/client`).
- **ORM:** [Drizzle ORM](mdc:https:/orm.drizzle.team) for schema definition, migrations, and type-safe queries ([drizzle.config.ts](mdc:drizzle.config.ts), schema in `drizzle/schema.ts`).
- **Location:** `drizzle/` directory for schema and migrations.

### 1.2. InfluxDB
- **Purpose:** Stores time-series data from evcc instances.
  - Sensor readings, charging states, energy measurements.
- **Technology:** Remote InfluxDB instance. Client library: `@influxdata/influxdb-client` ([package.json](mdc:package.json)).
- **Schema:** Dynamic, optimized for time-stamped data. Data is structured by Telegraf.
- **Location:** Code related to InfluxDB interaction is in `app/db/influx/`.

## 2. Data Ingestion Pipeline (evcc Data to InfluxDB)
This pipeline is crucial for getting structured time-series data into InfluxDB.
1.  **Data Source:** evcc instances.
2.  **Transmission:** Data sent via **MQTT** protocol to an MQTT broker (e.g., Mosquitto - external service).
3.  **Processing (Telegraf):** 
    - Telegraf (external service) subscribes to MQTT topics.
    - It parses and modifies incoming data (e.g., structuring topics, adding tags like `instance`, `componentId`, `aspect` from MQTT topic paths `evcc/<instance_id>/loadpoints/1/sessionPrice`).
    - This step is vital for data structure, collision avoidance, and query flexibility.
4.  **Storage:** Telegraf writes the structured data to InfluxDB.

## 3. Data Management & Access

### 3.1. InfluxDB Data Structure (via Telegraf)
- Telegraf rules (configured outside this repo) define how MQTT topics are mapped to InfluxDB measurements and tags.
- **Example Telegraf Rule Logic (from guide):**
  `[[inputs.mqtt_consumer.topic_parsing]]`
  `  topic = "evcc/+/loadpoints/+/+"`
  `  measurement = "_/_/measurement/_/_"` (e.g., `loadpoints`)
  `  tags = "_/instance/topic/componentId/aspect"`
- Queries to InfluxDB will leverage these tags for filtering and aggregation (e.g., in `app/db/influx/`).

### 3.2. SQLite Data Management
- Managed by Drizzle ORM: schema in `drizzle/schema.ts`, migrations in `drizzle/migrations/`.
- Used for CRUD operations on users, settings, and processed charging sessions.

### 3.3. CSV Data Import
- Supports import of historical charging data via CSV files.
- This functionality is likely handled by an admin-level route/handler (see `app/routes/api/instance/` or similar for data handling).

### 3.4. Frontend Data Handling & API Interaction
- **API Endpoints:** Backend provides data to frontend and a REST API for data export (e.g., extracted session data with HTTP Basic Auth). Endpoints are defined in `app/routes/api/`.
- **Server Handlers:** Logic for request processing can be found in `app/serverHandlers/`.
- **[TanStack Query](mdc:https:/tanstack.com/query/latest):** Used in the frontend for:
    - Data fetching from backend APIs.
    - Caching (client-side cache with ~30s validity as per guide).
    - Synchronization and background updates.
    - Pre-fetching data on hover for linked pages.
- **URL State Management:** Filter and sort configurations are stored in the URL by TanStack tools for shareability.

## 4. API Design & Best Practices
- **BFF Pattern:** TanStack Start serves as the BFF.
- **RESTful Principles:** For data export APIs and internal frontend-backend communication.
- **Authentication:** Secure API endpoints, especially for data export and admin functions.
- **Error Handling:** Implement robust error handling on the server and client.
- **Validation:** Use Zod for data validation (implied by `package.json` and common practice with TanStack tools).

Files related to API route definitions can be found in [app/routes/api/](mdc:app/routes/api), and server-side logic in [app/serverHandlers/](mdc:app/serverHandlers). Interactions with InfluxDB are likely encapsulated in [app/db/influx/](mdc:app/db/influx).
